{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "from IPython.display import display, Markdown\n",
    "from datetime import datetime\n",
    "import os\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/amyz/Desktop/calhacks/verba/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.14.3\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "print(sr.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "recognizer = sr.Recognizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=os.environ.get(\"AIzaSyAmxPnKEyytDM2mtFUenYGMD71GrEOA-Cw\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY_TERMS = [\n",
    "    'fire', 'medical', 'injury', 'accident', 'crash', 'location',\n",
    "    'victim', 'emergency', 'response', 'police', 'ambulance', 'hospital',\n",
    "    'car', 'truck', 'building', 'smoke', 'evacuation'\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_voice_input():\n",
    "    \"\"\"Capture voice input from microphone and return transcribed text.\"\"\"\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Listening for incident report... (Speak clearly, say 'stop' to finish)\")\n",
    "        recognizer.adjust_for_ambient_noise(source, duration=2)  # Adjust for noise\n",
    "        audio_data = []\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                print(\"Recording... Say your report or 'stop' to finish.\")\n",
    "                audio = recognizer.listen(source, timeout=5, phrase_time_limit=15)\n",
    "                print(\"Processing audio...\")\n",
    "                text = recognizer.recognize_google(audio)\n",
    "                print(f\"Transcribed: '{text}'\")\n",
    "                if 'stop' in text.lower():\n",
    "                    print(\"Detected 'stop'. Ending recording.\")\n",
    "                    break\n",
    "                audio_data.append(text)\n",
    "            except sr.WaitTimeoutError:\n",
    "                print(\"No speech detected for 5 seconds. Still listening...\")\n",
    "            except sr.UnknownValueError:\n",
    "                print(\"Could not understand audio, please repeat.\")\n",
    "            except sr.RequestError as e:\n",
    "                print(f\"Speech recognition error: {e}\")\n",
    "                return None\n",
    "            except Exception as e:\n",
    "                print(f\"Unexpected error: {e}\")\n",
    "                return None\n",
    "        return \" \".join(audio_data) if audio_data else None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening for incident report... (Speak clearly, say 'stop' to finish)\n",
      "Recording... Say your report or 'stop' to finish.\n",
      "Processing audio...\n",
      "Transcribed: 'higher on'\n",
      "Recording... Say your report or 'stop' to finish.\n",
      "Processing audio...\n",
      "Transcribed: 'fire on'\n",
      "Recording... Say your report or 'stop' to finish.\n",
      "Processing audio...\n",
      "Transcribed: 'Main Street 123'\n",
      "Recording... Say your report or 'stop' to finish.\n",
      "Processing audio...\n",
      "Unexpected error: [Errno 54] Connection reset by peer\n",
      "Final transcribed text: None\n"
     ]
    }
   ],
   "source": [
    "transcription = capture_voice_input()\n",
    "print(\"Final transcribed text:\", transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (327015777.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m```python\u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "```python\n",
    "# Cell 3: Parse Transcription with Letta (Updated for Dynamic Action Items)\n",
    "from letta_client import Letta\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize Letta client (global, to reuse across calls)\n",
    "client = Letta(\n",
    "    token=os.environ.get(\"LETTA_API_KEY\"),  # For Letta Cloud\n",
    "    base_url=os.environ.get(\"LETTA_BASE_URL\", \"http://localhost:8283\")  # For self-hosted\n",
    ")\n",
    "\n",
    "# Create Letta agent (global, to maintain state)\n",
    "agent = None\n",
    "def initialize_letta_agent():\n",
    "    global agent\n",
    "    if agent is None:\n",
    "        agent = client.agents.create(\n",
    "            memory_blocks=[\n",
    "                {\n",
    "                    \"label\": \"human\",\n",
    "                    \"value\": \"The responder is a first responder reporting incidents.\"\n",
    "                },\n",
    "                {\n",
    "                    \"label\": \"persona\",\n",
    "                    \"value\": \"I am an AI assistant for first responders, empathetic, clear, and professional. I deduce incident details from minimal input and generate tailored action items.\"\n",
    "                },\n",
    "                {\n",
    "                    \"label\": \"incident\",\n",
    "                    \"value\": \"No incident reported yet.\",\n",
    "                    \"description\": \"Stores context about the current incident being reported.\"\n",
    "                }\n",
    "            ],\n",
    "            tools=[\"web_search\"],  # Optional: for future real-time data\n",
    "            model=\"openai/gpt-4.1\",\n",
    "            embedding=\"openai/text-embedding-3-small\"\n",
    "        )\n",
    "    return agent\n",
    "\n",
    "def parse_transcription(voice_text):\n",
    "    \"\"\"Parse voice transcription into structured report fields using Letta agent with dynamic action items.\"\"\"\n",
    "    if not voice_text:\n",
    "        return None\n",
    "    \n",
    "    # Initialize agent\n",
    "    agent = initialize_letta_agent()\n",
    "    \n",
    "    # Prompt for full parsing with dynamic action items\n",
    "    prompt = f\"\"\"You are an AI assistant for first responders. Parse the following voice transcription to extract incident report fields, generate a narrative description, and reason about appropriate action items. Deduce as much as possible from minimal input. Use these guidelines:\n",
    "- incident_type: Identify as 'Fire', 'Medical Emergency', 'Traffic Accident', or 'Other' based on keywords like 'fire', 'injury', 'accident', 'crash'. If unclear, use 'Other'.\n",
    "- location: Identify any mentioned place (e.g., city, street, landmark). Capitalize properly. If unclear, use 'Not specified'.\n",
    "- number_of_victims: Identify the number of victims (e.g., 'two injured' means 2). Use 0 if not mentioned.\n",
    "- severity: Infer severity as 'Low', 'Moderate', 'High', or 'Not specified' based on context (e.g., 'injured' implies Moderate or High, 'fire' implies High).\n",
    "- actions_taken: Identify specific actions like 'evacuated', 'administered', 'transported', 'secured', 'responded', or infer from context (e.g., 'looking for' implies searching). Use 'Not specified' if unclear.\n",
    "- backup_needed: Determine if backup is needed (e.g., 'looking for back', 'additional units', 'need help' imply True). Use False if unclear.\n",
    "- action_items: Generate 2-3 specific, actionable tasks for first responders based on the incident context (e.g., incident type, victims, location, actions taken). Reason about the situation to suggest tasks that are practical and relevant (e.g., for a fire with victims, suggest 'Provide medical aid' and 'Contain the fire'). Use ['Assess the situation'] if context is insufficient.\n",
    "- narrative_description: Rewrite the transcription as a concise, professional narrative for an official report (e.g., 'A fire was reported at Main Street involving two injured victims, with a request for backup.'). If minimal input, generate a plausible narrative based on deduced fields.\n",
    "Return a JSON object with all fields. Use defaults as specified above if fields are unclear.\n",
    "\n",
    "Transcription: \"{voice_text}\"\n",
    "\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Send message to Letta agent\n",
    "        response = client.agents.messages.create(\n",
    "            agent_id=agent.id,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        \n",
    "        # Extract response\n",
    "        for msg in response.messages:\n",
    "            if msg.message_type == \"assistant_message\":\n",
    "                try:\n",
    "                    parsed_report = json.loads(msg.content)\n",
    "                    return {\n",
    "                        \"incident_type\": parsed_report.get(\"incident_type\", \"Other\"),\n",
    "                        \"location\": parsed_report.get(\"location\", \"Not specified\"),\n",
    "                        \"number_of_victims\": parsed_report.get(\"number_of_victims\", 0),\n",
    "                        \"severity\": parsed_report.get(\"severity\", \"Not specified\"),\n",
    "                        \"time\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                        \"description\": parsed_report.get(\"narrative_description\", voice_text),\n",
    "                        \"actions_taken\": parsed_report.get(\"actions_taken\", \"Not specified\"),\n",
    "                        \"backup_needed\": parsed_report.get(\"backup_needed\", False),\n",
    "                        \"action_items\": parsed_report.get(\"action_items\", [\"Assess the situation\"])\n",
    "                    }\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Error decoding Letta response: {msg.content}\")\n",
    "                    break\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing with Letta: {e}\")\n",
    "    \n",
    "    # Fallback parsing (no hardcoded action items)\n",
    "    text_lower = voice_text.lower()\n",
    "    report = {\n",
    "        \"incident_type\": \"Other\",\n",
    "        \"location\": \"Not specified\",\n",
    "        \"number_of_victims\": 0,\n",
    "        \"severity\": \"Not specified\",\n",
    "        \"time\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"description\": voice_text,\n",
    "        \"actions_taken\": \"Not specified\",\n",
    "        \"backup_needed\": False,\n",
    "        \"action_items\": [\"Assess the situation\"]\n",
    "    }\n",
    "    \n",
    "    # Incident type and severity\n",
    "    if 'fire' in text_lower:\n",
    "        report[\"incident_type\"] = \"Fire\"\n",
    "        report[\"severity\"] = \"High\"\n",
    "        report[\"description\"] = f\"A fire was reported{' at ' + location_match.group(1).capitalize() if 'at' in text_lower or 'in' in text_lower or 'near' in text_lower else ''}.\"\n",
    "    elif 'medical' in text_lower or 'injury' in text_lower:\n",
    "        report[\"incident_type\"] = \"Medical Emergency\"\n",
    "        report[\"severity\"] = \"Moderate\" if \"injury\" in text_lower else \"Not specified\"\n",
    "        report[\"description\"] = f\"A medical emergency was reported{' at ' + location_match.group(1).capitalize() if 'at' in text_lower or 'in' in text_lower or 'near' in text_lower else ''}.\"\n",
    "    elif 'accident' in text_lower or 'crash' in text_lower:\n",
    "        report[\"incident_type\"] = \"Traffic Accident\"\n",
    "        report[\"severity\"] = \"Moderate\"\n",
    "        report[\"description\"] = f\"A traffic accident was reported{' at ' + location_match.group(1).capitalize() if 'at' in text_lower or 'in' in text_lower or 'near' in text_lower else ''}.\"\n",
    "    \n",
    "    # Location\n",
    "    location_match = re.search(r\"(?:at|in|near)\\s+([a-zA-Z0-9\\s,]+)\", text_lower)\n",
    "    if location_match:\n",
    "        report[\"location\"] = location_match.group(1).capitalize()\n",
    "    \n",
    "    # Number of victims\n",
    "    victim_match = re.search(r'(\\d+)\\s*(?:injured|victim|victims)', text_lower)\n",
    "    if victim_match:\n",
    "        report[\"number_of_victims\"] = int(victim_match.group(1))\n",
    "        report[\"severity\"] = \"High\" if report[\"severity\"] == \"Not specified\" else report[\"severity\"]\n",
    "        report[\"description\"] += f\" Involving {report['number_of_victims']} victim{'s' if report['number_of_victims'] > 1 else ''}.\"\n",
    "    \n",
    "    # Actions taken\n",
    "    action_keywords = ['evacuated', 'administered', 'transported', 'secured', 'responded', 'looking for']\n",
    "    actions = [sentence.strip() for sentence in voice_text.split('.') if any(keyword in sentence.lower() for keyword in action_keywords)]\n",
    "    if actions:\n",
    "        report[\"actions_taken\"] = \" \".join(actions[:2])\n",
    "    \n",
    "    # Backup needed\n",
    "    if 'looking for back' in text_lower or 'additional units' in text_lower or 'need help' in text_lower or 'backup' in text_lower:\n",
    "        report[\"backup_needed\"] = True\n",
    "        report[\"description\"] += \" A request for backup was made.\"\n",
    "    \n",
    "    # Fallback action items (minimal, to avoid hardcoding)\n",
    "    if report[\"number_of_victims\"] > 0:\n",
    "        report[\"action_items\"] = [\"Provide medical aid\", \"Assess the situation\"]\n",
    "    if report[\"backup_needed\"]:\n",
    "        report[\"action_items\"] = [\"Request additional units\", \"Assess the situation\"]\n",
    "    \n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_text(voice_text):\n",
    "    \"\"\"Generate a concise summary of the voice transcription using Gemini.\"\"\"\n",
    "    if not voice_text:\n",
    "        return \"No input provided for summarization.\"\n",
    "    \n",
    "    prompt = f\"\"\"You are an AI assistant helping first responders summarize incident reports from voice transcriptions. Summarize the following transcription in 2-3 concise sentences, focusing on key details relevant to first responders (e.g., incident type, location, actions taken). Use clear, professional language suitable for an official report.\n",
    "\n",
    "Voice transcription: \"{voice_text}\"\n",
    "\"\"\"\n",
    "    try:\n",
    "        model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "        response = model.generate_content(prompt)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        print(f\"Error summarizing with Gemini: {e}\")\n",
    "        # Fallback to basic keyword-based summarization\n",
    "        sentences = re.split(r'[.!?]+', voice_text)\n",
    "        sentences = [s.strip() for s in sentences if s.strip()]\n",
    "        if not sentences:\n",
    "            return \"No valid sentences found for summarization.\"\n",
    "        scores = []\n",
    "        for sent in sentences:\n",
    "            sent_lower = sent.lower()\n",
    "            score = sum(1 for term in KEY_TERMS if term in sent_lower)\n",
    "            word_count = len(sent_lower.split())\n",
    "            length_penalty = 1.0 if 5 <= word_count <= 20 else 0.5\n",
    "            scores.append(score * length_penalty)\n",
    "        top_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:2]\n",
    "        summary_sentences = [sentences[i] for i in top_indices]\n",
    "        return \" \".join(summary_sentences) if summary_sentences else \"Unable to generate summary.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_report(report_data, summary):\n",
    "    \"\"\"Generate a markdown report from structured data and save to file.\"\"\"\n",
    "    if not report_data:\n",
    "        return \"No report data provided.\"\n",
    "    \n",
    "    markdown = f\"\"\"# Incident Report\n",
    "**Date and Time:** {report_data['time']}\n",
    "**Incident Type:** {report_data['incident_type']}\n",
    "**Location:** {report_data['location']}\n",
    "**Description:** {report_data['description']}\n",
    "**Actions Taken:** {report_data['actions_taken']}\n",
    "**Summary:** {summary}\n",
    "\"\"\"\n",
    "    # Save to file with timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"incident_report_{timestamp}.md\"\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(markdown)\n",
    "    print(f\"Report saved as {filename}\")\n",
    "    return markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'letta_client'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyttsx3\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtime\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mletta_client\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Letta\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mspeak_text\u001b[39m(text):\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'letta_client'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEXT TO SPEECH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting interactive voice agent... Speak clearly, say 'done' to proceed or 'stop' to end.\n",
      "\n",
      "Prompt: Please describe the type of incident, such as fire, medical emergency, or traffic accident.\n",
      "Listening for incident report... (Speak clearly, say 'stop' to finish)\n",
      "Recording... Say your report or 'stop' to finish.\n",
      "Processing audio...\n",
      "Transcribed: 'there was a'\n",
      "Recording... Say your report or 'stop' to finish.\n",
      "Processing audio...\n",
      "Transcribed: 'a medical emergency'\n",
      "Recording... Say your report or 'stop' to finish.\n",
      "Processing audio...\n",
      "Transcribed: 'there was a fire'\n",
      "Recording... Say your report or 'stop' to finish.\n",
      "Processing audio...\n",
      "Transcribed: 'two people are injured and I need backup'\n",
      "Recording... Say your report or 'stop' to finish.\n",
      "Processing audio...\n",
      "Transcribed: 'I don't know what to do next please tell me'\n",
      "Recording... Say your report or 'stop' to finish.\n",
      "No speech detected for 5 seconds. Still listening...\n",
      "Recording... Say your report or 'stop' to finish.\n",
      "Processing audio...\n",
      "Could not understand audio, please repeat.\n",
      "Recording... Say your report or 'stop' to finish.\n",
      "Processing audio...\n",
      "Transcribed: 'stop'\n",
      "Detected 'stop'. Ending recording.\n",
      "Error parsing with Gemini for incident_type: \n",
      "  No API_KEY or ADC found. Please either:\n",
      "    - Set the `GOOGLE_API_KEY` environment variable.\n",
      "    - Manually pass the key with `genai.configure(api_key=my_api_key)`.\n",
      "    - Or set up Application Default Credentials, see https://ai.google.dev/gemini-api/docs/oauth for more information.\n",
      "Confirmation: I understood incident type as Fire. Is this correct? Say 'yes', 'no', or 'done' to proceed.\n",
      "Listening for incident report... (Speak clearly, say 'stop' to finish)\n",
      "Recording... Say your report or 'stop' to finish.\n",
      "Processing audio...\n",
      "Transcribed: 'yes'\n",
      "Recording... Say your report or 'stop' to finish.\n",
      "Processing audio...\n",
      "Could not understand audio, please repeat.\n",
      "Recording... Say your report or 'stop' to finish.\n",
      "Processing audio...\n",
      "Transcribed: 'stop'\n",
      "Detected 'stop'. Ending recording.\n",
      "\n",
      "Prompt: Please provide the location of the incident, such as the street or landmark.\n",
      "Listening for incident report... (Speak clearly, say 'stop' to finish)\n",
      "Recording... Say your report or 'stop' to finish.\n",
      "No speech detected for 5 seconds. Still listening...\n",
      "Recording... Say your report or 'stop' to finish.\n",
      "Processing audio...\n",
      "Transcribed: 'Main Street'\n",
      "Recording... Say your report or 'stop' to finish.\n",
      "Processing audio...\n",
      "Transcribed: 'stop'\n",
      "Detected 'stop'. Ending recording.\n",
      "Error parsing with Gemini for location: \n",
      "  No API_KEY or ADC found. Please either:\n",
      "    - Set the `GOOGLE_API_KEY` environment variable.\n",
      "    - Manually pass the key with `genai.configure(api_key=my_api_key)`.\n",
      "    - Or set up Application Default Credentials, see https://ai.google.dev/gemini-api/docs/oauth for more information.\n",
      "Confirmation: I understood location as Street. Is this correct? Say 'yes', 'no', or 'done' to proceed.\n",
      "Listening for incident report... (Speak clearly, say 'stop' to finish)\n",
      "Recording... Say your report or 'stop' to finish.\n",
      "Processing audio...\n",
      "Transcribed: 'done'\n",
      "Recording... Say your report or 'stop' to finish.\n",
      "Processing audio...\n",
      "Transcribed: 'stop'\n",
      "Detected 'stop'. Ending recording.\n",
      "\n",
      "Prompt: How many victims are involved? For example, say 'two injured'.\n",
      "Listening for incident report... (Speak clearly, say 'stop' to finish)\n",
      "Recording... Say your report or 'stop' to finish.\n",
      "Processing audio...\n",
      "Transcribed: 'too injured'\n",
      "Recording... Say your report or 'stop' to finish.\n",
      "No speech detected for 5 seconds. Still listening...\n",
      "Recording... Say your report or 'stop' to finish.\n",
      "Processing audio...\n",
      "Transcribed: 'stop'\n",
      "Detected 'stop'. Ending recording.\n",
      "Error parsing with Gemini for number_of_victims: \n",
      "  No API_KEY or ADC found. Please either:\n",
      "    - Set the `GOOGLE_API_KEY` environment variable.\n",
      "    - Manually pass the key with `genai.configure(api_key=my_api_key)`.\n",
      "    - Or set up Application Default Credentials, see https://ai.google.dev/gemini-api/docs/oauth for more information.\n",
      "Confirmation: I understood number of victims as 0. Is this correct? Say 'yes', 'no', or 'done' to proceed.\n",
      "Listening for incident report... (Speak clearly, say 'stop' to finish)\n",
      "Recording... Say your report or 'stop' to finish.\n",
      "Processing audio...\n",
      "Transcribed: 'done'\n",
      "Recording... Say your report or 'stop' to finish.\n",
      "Processing audio...\n",
      "Transcribed: 'stop'\n",
      "Detected 'stop'. Ending recording.\n",
      "\n",
      "Prompt: What actions have been taken, such as evacuated or transported?\n",
      "Listening for incident report... (Speak clearly, say 'stop' to finish)\n",
      "Recording... Say your report or 'stop' to finish.\n",
      "Processing audio...\n",
      "Transcribed: 'no'\n",
      "Recording... Say your report or 'stop' to finish.\n",
      "Processing audio...\n",
      "Transcribed: 'no actions'\n",
      "Recording... Say your report or 'stop' to finish.\n",
      "Processing audio...\n",
      "Transcribed: 'stop'\n",
      "Detected 'stop'. Ending recording.\n",
      "Error parsing with Gemini for actions_taken: \n",
      "  No API_KEY or ADC found. Please either:\n",
      "    - Set the `GOOGLE_API_KEY` environment variable.\n",
      "    - Manually pass the key with `genai.configure(api_key=my_api_key)`.\n",
      "    - Or set up Application Default Credentials, see https://ai.google.dev/gemini-api/docs/oauth for more information.\n",
      "Confirmation: I understood actions taken as Not specified. Is this correct? Say 'yes', 'no', or 'done' to proceed.\n",
      "Listening for incident report... (Speak clearly, say 'stop' to finish)\n",
      "Recording... Say your report or 'stop' to finish.\n",
      "No speech detected for 5 seconds. Still listening...\n",
      "Recording... Say your report or 'stop' to finish.\n",
      "Processing audio...\n",
      "Transcribed: 'yes stop'\n",
      "Detected 'stop'. Ending recording.\n",
      "\n",
      "Prompt: Do you need backup? For example, say 'need additional units' or 'no backup needed'.\n",
      "Listening for incident report... (Speak clearly, say 'stop' to finish)\n",
      "Recording... Say your report or 'stop' to finish.\n",
      "Processing audio...\n",
      "Transcribed: 'no backup needed'\n",
      "Recording... Say your report or 'stop' to finish.\n",
      "Processing audio...\n",
      "Transcribed: 'stop'\n",
      "Detected 'stop'. Ending recording.\n",
      "Error parsing with Gemini for backup_needed: \n",
      "  No API_KEY or ADC found. Please either:\n",
      "    - Set the `GOOGLE_API_KEY` environment variable.\n",
      "    - Manually pass the key with `genai.configure(api_key=my_api_key)`.\n",
      "    - Or set up Application Default Credentials, see https://ai.google.dev/gemini-api/docs/oauth for more information.\n",
      "Confirmation: I understood backup needed as False. Is this correct? Say 'yes', 'no', or 'done' to proceed.\n",
      "Listening for incident report... (Speak clearly, say 'stop' to finish)\n",
      "Recording... Say your report or 'stop' to finish.\n",
      "No speech detected for 5 seconds. Still listening...\n",
      "Recording... Say your report or 'stop' to finish.\n",
      "Processing audio...\n",
      "Transcribed: 'yes'\n",
      "Recording... Say your report or 'stop' to finish.\n",
      "No speech detected for 5 seconds. Still listening...\n",
      "Recording... Say your report or 'stop' to finish.\n",
      "Processing audio...\n",
      "Transcribed: 'stop'\n",
      "Detected 'stop'. Ending recording.\n",
      "Error parsing with Gemini for full report: \n",
      "  No API_KEY or ADC found. Please either:\n",
      "    - Set the `GOOGLE_API_KEY` environment variable.\n",
      "    - Manually pass the key with `genai.configure(api_key=my_api_key)`.\n",
      "    - Or set up Application Default Credentials, see https://ai.google.dev/gemini-api/docs/oauth for more information.\n",
      "\n",
      "Summarizing report...\n",
      "Error summarizing with Gemini: \n",
      "  No API_KEY or ADC found. Please either:\n",
      "    - Set the `GOOGLE_API_KEY` environment variable.\n",
      "    - Manually pass the key with `genai.configure(api_key=my_api_key)`.\n",
      "    - Or set up Application Default Credentials, see https://ai.google.dev/gemini-api/docs/oauth for more information.\n",
      "\n",
      "Generating report...\n",
      "Report saved as incident_report_20250620_225942.md\n",
      "\n",
      "Report Content:\n",
      "# Incident Report\n",
      "**Date and Time:** 2025-06-20 22:54:39\n",
      "**Incident Type:** Fire\n",
      "**Location:** Street\n",
      "**Description:** there was a a medical emergency there was a fire two people are injured and I need backup I don't know what to do next please tell me Main Street too injured no no actions no backup needed\n",
      "**Actions Taken:** Not specified\n",
      "**Summary:** there was a a medical emergency there was a fire two people are injured and I need backup I don't know what to do next please tell me Main Street too injured no no actions no backup needed\n",
      "\n",
      "Report saved. Action items: Secure the area, Request fire suppression units. No backup requested.\n"
     ]
    }
   ],
   "source": [
    "def speak_text(text):\n",
    "    \"\"\"Speak the given text using text-to-speech.\"\"\"\n",
    "    try:\n",
    "        engine = pyttsx3.init()\n",
    "        engine.setProperty('rate', 150)  # Speed of speech\n",
    "        engine.setProperty('volume', 0.9)  # Volume (0.0 to 1.0)\n",
    "        engine.say(text)\n",
    "        engine.runAndWait()\n",
    "    except Exception as e:\n",
    "        print(f\"Error in text-to-speech: {e}\")\n",
    "\n",
    "def run_interactive_voice_agent():\n",
    "    \"\"\"Run an interactive voice agent to collect and confirm incident report details.\"\"\"\n",
    "    try:\n",
    "        # Initialize report data\n",
    "        report_data = {\n",
    "            \"incident_type\": \"Not specified\",\n",
    "            \"location\": \"Not specified\",\n",
    "            \"number_of_victims\": 0,\n",
    "            \"severity\": \"Not specified\",\n",
    "            \"time\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            \"description\": \"\",\n",
    "            \"actions_taken\": \"Not specified\",\n",
    "            \"backup_needed\": False,\n",
    "            \"action_items\": [\"None specified\"]\n",
    "        }\n",
    "        \n",
    "        # Welcome message\n",
    "        speak_text(\"Welcome, first responder. I will guide you through creating an incident report. Please speak clearly and say 'done' to move to the next field or 'stop' to end.\")\n",
    "        print(\"Starting interactive voice agent... Speak clearly, say 'done' to proceed or 'stop' to end.\")\n",
    "        \n",
    "        # Fields to collect\n",
    "        fields = [\n",
    "            (\"incident_type\", \"Please describe the type of incident, such as fire, medical emergency, or traffic accident.\"),\n",
    "            (\"location\", \"Please provide the location of the incident, such as the street or landmark.\"),\n",
    "            (\"number_of_victims\", \"How many victims are involved? For example, say 'two injured'.\"),\n",
    "            (\"actions_taken\", \"What actions have been taken, such as evacuated or transported?\"),\n",
    "            (\"backup_needed\", \"Do you need backup? For example, say 'need additional units' or 'no backup needed'.\")\n",
    "        ]\n",
    "        \n",
    "        descriptions = []\n",
    "        \n",
    "        for field, prompt in fields:\n",
    "            while True:\n",
    "                speak_text(prompt)\n",
    "                print(f\"\\nPrompt: {prompt}\")\n",
    "                voice_text = capture_voice_input()\n",
    "                \n",
    "                if not voice_text:\n",
    "                    speak_text(\"No input detected. Please try again or say 'stop' to end.\")\n",
    "                    print(\"No input detected. Try again or say 'stop'.\")\n",
    "                    continue\n",
    "                \n",
    "                if 'stop' in voice_text.lower():\n",
    "                    speak_text(\"Stopping report creation.\")\n",
    "                    print(\"Report creation stopped.\")\n",
    "                    return\n",
    "                \n",
    "                if 'done' in voice_text.lower():\n",
    "                    if field == \"incident_type\" and report_data[\"incident_type\"] == \"Not specified\":\n",
    "                        speak_text(\"Incident type is required. Please provide it now.\")\n",
    "                        print(\"Incident type is required. Try again.\")\n",
    "                        continue\n",
    "                    break\n",
    "                \n",
    "                # Parse the specific field\n",
    "                result = parse_transcription(voice_text, field)\n",
    "                if field == \"number_of_victims\":\n",
    "                    report_data[field] = result if isinstance(result, int) else 0\n",
    "                elif field == \"backup_needed\":\n",
    "                    report_data[field] = result if isinstance(result, bool) else False\n",
    "                else:\n",
    "                    report_data[field] = result if result != \"Not specified\" else report_data[field]\n",
    "                \n",
    "                # Update description\n",
    "                descriptions.append(voice_text)\n",
    "                \n",
    "                # Confirm the parsed result\n",
    "                confirmation = f\"I understood {field.replace('_', ' ')} as {result}. Is this correct? Say 'yes', 'no', or 'done' to proceed.\"\n",
    "                speak_text(confirmation)\n",
    "                print(f\"Confirmation: {confirmation}\")\n",
    "                \n",
    "                confirmation_input = capture_voice_input()\n",
    "                if not confirmation_input or 'yes' in confirmation_input.lower() or 'done' in confirmation_input.lower():\n",
    "                    break\n",
    "                elif 'no' in confirmation_input.lower():\n",
    "                    speak_text(f\"Please repeat the {field.replace('_', ' ')}.\")\n",
    "                    print(f\"Repeating prompt for {field}.\")\n",
    "                    continue\n",
    "                elif 'stop' in confirmation_input.lower():\n",
    "                    speak_text(\"Stopping report creation.\")\n",
    "                    print(\"Report creation stopped.\")\n",
    "                    return\n",
    "        \n",
    "        # Set description\n",
    "        report_data[\"description\"] = \" \".join(descriptions) if descriptions else \"Not specified\"\n",
    "        \n",
    "        # Infer severity and action items if not already set\n",
    "        if report_data[\"incident_type\"] != \"Not specified\":\n",
    "            full_report = parse_transcription(report_data[\"description\"])\n",
    "            report_data[\"severity\"] = full_report[\"severity\"]\n",
    "            report_data[\"action_items\"] = full_report[\"action_items\"]\n",
    "        \n",
    "        # Summarize the report\n",
    "        speak_text(\"Generating summary of the incident report.\")\n",
    "        print(\"\\nSummarizing report...\")\n",
    "        summary = summarize_text(report_data[\"description\"])\n",
    "        \n",
    "        # Generate and save the report\n",
    "        speak_text(\"Generating and saving the incident report.\")\n",
    "        print(\"\\nGenerating report...\")\n",
    "        report = generate_report(report_data, summary)\n",
    "        print(\"\\nReport Content:\")\n",
    "        print(report)\n",
    "        \n",
    "        # Provide final guidance\n",
    "        guidance = f\"Report saved. Action items: {', '.join(report_data['action_items'])}. \"\n",
    "        if report_data[\"backup_needed\"]:\n",
    "            guidance += \"Backup has been requested. Please confirm with dispatch.\"\n",
    "        else:\n",
    "            guidance += \"No backup requested.\"\n",
    "        speak_text(guidance)\n",
    "        print(guidance)\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_message = f\"An error occurred during execution: {e}\"\n",
    "        speak_text(error_message)\n",
    "        print(error_message)\n",
    "\n",
    "# Run the interactive voice agent\n",
    "run_interactive_voice_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
